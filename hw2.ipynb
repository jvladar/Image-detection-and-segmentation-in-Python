{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d80532-7589-466b-8315-7243b788a264",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Autumn 2021 - Home Assignment 2\n",
    "\n",
    "**Ondřej Schejbal & Jan Vladár**\n",
    "\n",
    "In our assigned we deal with problem of image detection and segmentation. We apply different approaches for template matching, descriptor detection and image segmentation of selected sea plants.\n",
    "\n",
    "For our project we decided to work with these 2 plant species:\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Zostera\">Zostera</a>\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Zostera\">Mytilus</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19787c28-0338-46ec-be03-2407c0342404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class1FolderName = './Mytilus_original'\n",
    "class2FolderName = './Zostera_original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e6ce7e-3a0c-44f8-963a-b8e80b326c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the output images larger\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8372b775-9ef3-4d77-917a-fb2aa10961ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolderNameAndEtalonFolderName(classFolderName, print_it=False):\n",
    "    folderName = classFolderName[:-9]\n",
    "    etalonFolderName = folderName + 'Etalons'\n",
    "    if print_it:\n",
    "        print('Folder name:', folderName, '\\r\\nEtalon folder name:', etalonFolderName)\n",
    "    return folderName, etalonFolderName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0896e4-e6a6-403f-bf2c-4a45a1eda3c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 1\n",
    "*Collect a set of images suitable for the tasks below of at least 2 species. Write code to preprocess the \n",
    "images of plants into a uniform size of your choice, e.g. 1024x1024 pixels.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddf4cd",
   "metadata": {},
   "source": [
    "We have searched for relevant **Zostera** and **Mytilus** images on the web, but most of the pictures contained either some form of watermark, or some additional image distortion. Because of that we were left with only limited number of images for our task. This most likely had significant impact, especially on the deep neural network solution described in [part 4](#part_4) and that's why we decided to use data agmentation for that part of our assignment.\n",
    "\n",
    "In the code below we are transforming the images into recommended dimensions 1024x1024 while also converting them to the *.png* format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9029bc-087d-4975-b540-d8f85ee19482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformImagesInDirectory(folderName):\n",
    "    list_of_files = os.listdir(folderName)\n",
    "    targetFolderName = folderName[:-9]\n",
    "    for idx, file in enumerate(list_of_files):\n",
    "        image_file_name = os.path.join(folderName, file)\n",
    "        img = Image.open(image_file_name)  # .convert(\"L\")\n",
    "        img = img.resize((1024, 1024))\n",
    "        if not os.path.exists(targetFolderName):\n",
    "            os.mkdir(targetFolderName)\n",
    "        img.save(targetFolderName + '/' + str(idx) + \".png\")\n",
    "        # os.remove(image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec1af1a-5d0b-4820-9e4f-34a9fc67682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1():\n",
    "    transformImagesInDirectory(class1FolderName)\n",
    "    transformImagesInDirectory(class2FolderName)\n",
    "# task1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545741c-f4dc-4ec5-9d04-38a6a9babf67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2\n",
    "*Select a set of etalons (e.g. small images containing a sample of some distinctive features) from the \n",
    "an image to be used for matching similar objects. Aim for a set that would be representative on at \n",
    "least 50% of the images of the particular species. Think how to deal with rotations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e74f6",
   "metadata": {},
   "source": [
    "In this task we have manually created 9 etalons for each selected sea plant. We have selected the etalons as small as possible, but still containing representative and dominant part of given plants visual.\n",
    "\n",
    "For Mytilus this was quite simple, but for Zostera it was not. Zostera is basically a sea grass and selecting only one grass stalk was sometimes very challenging. We have also decided to create Zostera etalons from different parts of the grass stalks - from the top, middle and bottom of the stalk.\n",
    "\n",
    "When selecting the etalons our goal was to have a selection of small pieces from our images, which would have enough representative characteristic needed for succesfull template matching with at least 50 % accuracy for the respective plant species.\n",
    "\n",
    "In the cells below you can see us matching the created etalons one by one to each image in our dataset. We have used the opencv2 <a href=\"https://docs.opencv.org/4.x/df/dfb/group__imgproc__object.html#ga586ebfb0a7fb604b35a23d85391329be\">matchTemplate</a> function. This function has many matching methods and after some experiments and studying the differences between them we have decided to use the **TM_CCOEFF_NORMED** match method for this task, which represents the normalized value of correlation coefficient between the images.\n",
    "\n",
    "<p style=\"display:none\">https://stackoverflow.com/questions/55469431/what-does-the-tm-ccorr-and-tm-ccoeff-in-opencv-mean</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b824b",
   "metadata": {},
   "source": [
    "**Resolution**: We were able to achieve ~60 % of accuracy for Zostera and ~55 % accuracy for Mytilus.\n",
    "\n",
    "We have also experimented with etalons. We observed that modifying the size significantly affects the accuracy. When the etalons were much bigger, the accuracy became significantly lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c87ccb-d97b-41e6-8d58-3d51717f94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_image(img, template):\n",
    "    w, h = template.shape[::-1]\n",
    "    match_method = cv2.TM_CCOEFF_NORMED\n",
    "    res = cv2.matchTemplate(img, template, match_method)\n",
    "    _, maxval, _, maxloc = cv2.minMaxLoc(res)\n",
    "    btm_right = (maxloc[0] + w, maxloc[1] + h)\n",
    "    cv2.rectangle(img, maxloc, btm_right, 255, 2)\n",
    "    return maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c56360a9-ae76-4863-a110-bf483163508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchEtalonToEachImage(etalons, images):\n",
    "    # matching_results = []\n",
    "    matching_results_by_etalon = []\n",
    "    for etalon_name in os.listdir(etalons):\n",
    "        etalon_path = etalons + \"/\" + etalon_name\n",
    "        # print(\"etalon:\", etalon_path)\n",
    "        img_template = cv2.imread(etalon_path, 0) \n",
    "        matching_results = []\n",
    "        for image_name in os.listdir(images):\n",
    "            img_path = images + \"/\" + image_name\n",
    "            # print(\"\\t img\", img_path)\n",
    "            img = cv2.imread(img_path, 0)\n",
    "            match_res = match_image(img, img_template)\n",
    "            matching_results.append(match_res)\n",
    "        matching_results_by_etalon.append(matching_results)\n",
    "\n",
    "    averages = []\n",
    "\n",
    "    for val in matching_results_by_etalon:\n",
    "        averages.append(np.average(val))\n",
    "    print(\"Precision:\", np.average(averages) * 100)\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e28264-0ddd-4849-a64e-b3e03a72889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mytilus\n",
      "Precision: 54.667162322081055\n",
      "Zostera\n",
      "Precision: 59.799787082842414\n"
     ]
    }
   ],
   "source": [
    "def task2(classFolderName):\n",
    "    folderName, etalonFolderName = getFolderNameAndEtalonFolderName(classFolderName)\n",
    "    precisionForEachEtalonList = matchEtalonToEachImage(etalonFolderName, folderName)\n",
    "    # print(\"Precisions for each etalon:\", precisionForEachEtalonList)\n",
    "\n",
    "print(\"Mytilus\")\n",
    "task2(class1FolderName)\n",
    "\n",
    "print(\"Zostera\")\n",
    "task2(class2FolderName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544597b-1735-4336-8095-10fc3638575e",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Use at least 3 different existing conventional feature detectors provided by \n",
    "OpenCV to find matches of the etalons in the image. NB! Take into account overlaps and subtract the \n",
    "appropriate numbers from total scores.\n",
    "\n",
    "Evaluate on two different images (called task3a.tiff and task3b.tiff) how well the approach works and \n",
    "which feature detector performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370db196",
   "metadata": {},
   "source": [
    "For this task we have used 3 different approaches:\n",
    "1. SIFT with FlannBased matching\n",
    "2. ORB\n",
    "3. SIFT with BruteForce matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a541c-9052-4fdc-baca-1ce5da61cc5e",
   "metadata": {},
   "source": [
    "## Task 4<a id='part_4'></a>\n",
    "*Improve the baseline by applying deep learning.*\n",
    "\n",
    "**TODO REMOVE THE REST**\n",
    "\n",
    "\n",
    "Key words: OpenCV 4, OpenVINO, ONNX, \n",
    "Tensorflow, PyTorch. The result needs to be documented, i.e. you should present quantitative results \n",
    "in a report where you show if and how much the deep learning approach improved your baseline. \n",
    "\n",
    "Make sure to use appropriate criteria for the measurement!\n",
    "\n",
    "NB! Aim at using a pretrained network as a basis and apply the concept of transfer learning to adjust \n",
    "the net for your task.\n",
    "\n",
    "NB! The work needs to be documented, i.e. you need to include a report where you have \n",
    "quantitative results of your baseline and improvement in addition to the description of the approach \n",
    "taken.\n",
    "\n",
    "To store images in the Git repository you should use Git LFS support.\n",
    "You may use the AI-Lab environment for GPU accelerated computations.*\n",
    "\n",
    "\n",
    "**Helpful hints:**\n",
    "\n",
    "Labling tool: CVAT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
